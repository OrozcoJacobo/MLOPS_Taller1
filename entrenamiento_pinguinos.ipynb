{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53c55acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, json, joblib\n",
    "from palmerpenguins import load_penguins\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43cae22",
   "metadata": {},
   "source": [
    "# Primer Taller MLOPS \n",
    "Presentador por Jacobo & Javier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8c11ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>39.6</td>\n",
       "      <td>20.7</td>\n",
       "      <td>191.0</td>\n",
       "      <td>3900.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>35.5</td>\n",
       "      <td>16.2</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3350.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>48.4</td>\n",
       "      <td>16.3</td>\n",
       "      <td>220.0</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>46.4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>4700.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>37.8</td>\n",
       "      <td>18.3</td>\n",
       "      <td>174.0</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>43.3</td>\n",
       "      <td>14.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>4575.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>35.5</td>\n",
       "      <td>17.5</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3700.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>42.9</td>\n",
       "      <td>13.1</td>\n",
       "      <td>215.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>45.8</td>\n",
       "      <td>14.6</td>\n",
       "      <td>210.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "114  Adelie     Biscoe            39.6           20.7              191.0   \n",
       "66   Adelie     Biscoe            35.5           16.2              195.0   \n",
       "2    Adelie  Torgersen            40.3           18.0              195.0   \n",
       "187  Gentoo     Biscoe            48.4           16.3              220.0   \n",
       "226  Gentoo     Biscoe            46.4           15.0              216.0   \n",
       "20   Adelie     Biscoe            37.8           18.3              174.0   \n",
       "260  Gentoo     Biscoe            43.3           14.0              208.0   \n",
       "74   Adelie  Torgersen            35.5           17.5              190.0   \n",
       "176  Gentoo     Biscoe            42.9           13.1              215.0   \n",
       "166  Gentoo     Biscoe            45.8           14.6              210.0   \n",
       "\n",
       "     body_mass_g     sex  year  \n",
       "114       3900.0  female  2009  \n",
       "66        3350.0  female  2008  \n",
       "2         3250.0  female  2007  \n",
       "187       5400.0    male  2008  \n",
       "226       4700.0  female  2008  \n",
       "20        3400.0  female  2007  \n",
       "260       4575.0  female  2009  \n",
       "74        3700.0  female  2008  \n",
       "176       5000.0  female  2007  \n",
       "166       4200.0  female  2007  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penguins_df_raw = load_penguins()\n",
    "penguins_df_raw.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2565ef07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "species               0\n",
       "island                0\n",
       "bill_length_mm        2\n",
       "bill_depth_mm         2\n",
       "flipper_length_mm     2\n",
       "body_mass_g           2\n",
       "sex                  11\n",
       "year                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penguins_df_raw.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a560f4",
   "metadata": {},
   "source": [
    "## Dataset Primeras Impresiones\n",
    "Dando un primer vistazo al dataset podemos identificar que tienes la siguientes features:\n",
    "1. Numericas: bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g, year\n",
    "2. Categóricas: island, sex\n",
    "3. Target: species\n",
    "\n",
    "Inicialmente proponemos el siguiente tratamiento:\n",
    "1. Imputar numericas con median\n",
    "2. Imputar categorias con most_frequent\n",
    "3. OneHot a categoricas\n",
    "\n",
    "Para el entrenamiento de diversos modelos, realizamos la siguiente propuesta inicialmente, que podria cambiar dependiendo de su performance, aunque como obtener el mejor performance no es el objetivo de este taller probablemente nos mantengamos con estos:\n",
    "1. Logistic Regression\n",
    "2. Random Forest\n",
    "3. SVC\n",
    "4. Gradient Boosting\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eac5f91",
   "metadata": {},
   "source": [
    "Separamos las variables X y el target y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acd759d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = penguins_df_raw.drop(\"species\", axis = 1) #datos de entrada\n",
    "y = penguins_df_raw[\"species\"] # variable a predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3ff3048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      island  bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g  \\\n",
       "0  Torgersen            39.1           18.7              181.0       3750.0   \n",
       "1  Torgersen            39.5           17.4              186.0       3800.0   \n",
       "2  Torgersen            40.3           18.0              195.0       3250.0   \n",
       "3  Torgersen             NaN            NaN                NaN          NaN   \n",
       "4  Torgersen            36.7           19.3              193.0       3450.0   \n",
       "\n",
       "      sex  year  \n",
       "0    male  2007  \n",
       "1  female  2007  \n",
       "2  female  2007  \n",
       "3     NaN  2007  \n",
       "4  female  2007  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53e66955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Adelie\n",
       "1    Adelie\n",
       "2    Adelie\n",
       "3    Adelie\n",
       "4    Adelie\n",
       "Name: species, dtype: str"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bd3b7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    stratify=y, #usamos stratify porque species es multiclase (adelie, gentoo, chinstrap), y esto amnetiene la proporcion de clases en train y validation\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "005944a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275, 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9e8cf70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae49d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline para variables numéricas\n",
    "numeric_transformer = Pipeline( #un pipeline es simplemente una lista ordenada de pasos que se ejecutan uno tras otro\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")) #aqui decimos para las variables numericas aplica un imputador que reemplace los valores faltantes con la mediana\n",
    "    ]\n",
    ")\n",
    "\n",
    "#cuando entrenemos el modelo el pipeline:\n",
    "    #1. calcula la mediana usando solo los datos de entrenamiento\n",
    "    #2. guarda esa mediana internamente\n",
    "    #3. cuando llegue un nuevo dato en produccion, usa esa misma mediana\n",
    "\n",
    "# Pipeline para variables categóricas\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Aqui tenemos dos pasos\n",
    "    #1. si sex es nan, lo reemplaza por el valor mas frecuente\n",
    "    #2. convierte variables categoricas en columnas binarias | handle_unknown=\"ignore\", si aparece una isla nueva que nuncca vimos la ignora\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4903072",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\n",
    "    \"bill_length_mm\",\n",
    "    \"bill_depth_mm\",\n",
    "    \"flipper_length_mm\",\n",
    "    \"body_mass_g\",\n",
    "    \"year\"\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    \"island\",\n",
    "    \"sex\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8eec48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer( #este objeto aplica transformaciones diferentes a diferentes columnas automaticamente\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features), # a las columnas numericas aplica numeric_transformer\n",
    "        (\"cat\", categorical_transformer, categorical_features) # a las columnas categoricas aplica categorical_transformer\n",
    "    ]\n",
    ") \n",
    "#junta todo en una sola matriz para el modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658ce926",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/OAP/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:406: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg -> val accuracy: 1.0000\n",
      "rf -> val accuracy: 1.0000\n",
      "svm -> val accuracy: 0.7681\n",
      "gb -> val accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "models = { #diccionario donde la clave es el nombre del modelo y el valor es la instancia del clasificador, esto para poderlos entrenar en un loop y no tener que reescribir codigo\n",
    "    \"logreg\": LogisticRegression(max_iter=1000),\n",
    "    \"rf\": RandomForestClassifier(random_state=42),\n",
    "    \"svm\": SVC(probability=True, random_state=42),\n",
    "    \"gb\": GradientBoostingClassifier(random_state=42),\n",
    "}\n",
    "\n",
    "trained_models = {} # diccionario vacio para guardar los modelos ya entrenados\n",
    "\n",
    "for name, clf in models.items(): #iterar sobre cada modelo, ej: primera iteracion -> name = \"logreg\", clf = LogisticRegression(max_iter = 1000)\n",
    "    pipe = Pipeline(steps=[ #creamos un pipeline que hace 1. preprocesamiento y 2. clasificacion\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", clf)\n",
    "    ])\n",
    "    # cuando llegue aqui, internamente el preprocessor aprende: 1. mediandas, moda, categorias para one-hot, 2. transforma los datos, 3. el modelo se entrena con datos transformados\n",
    "    pipe.fit(X_train, y_train) # en resumen aqui ejecuta, 1. imputacion, 2. enconding, 3. transformacion, 4. entrenamiento del modelo \n",
    "    #IMPORTANTE: el preprocesamiento se ajusto SOLO con X_trian para evitar data leakage\n",
    "\n",
    "    preds = pipe.predict(X_val) #el pipeline transforma automaticamente X_val, el modelo predice\n",
    "    acc = accuracy_score(y_val, preds) #calculamos accuracy\n",
    "    #Nota para javier: igual para este taller el accuracy no importa mucho, solo pongamoslo como buena practica\n",
    "\n",
    "    trained_models[name] = pipe #guardar el pipeline completo entrenado, no solo el clasificador sino preprocessor + modelo\n",
    "\n",
    "    print(f\"{name} -> val accuracy: {acc:.4f}\")#mostrar resultados\n",
    "    #Nota para javier: tenemos overfitting obviamente, pero bueno no vamos a perder tiempo entrenando modelos perfectos porque lo que importa es el deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb29cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelos guardados en /models\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "for name, pipe in trained_models.items():\n",
    "    joblib.dump(pipe, f\"models/{name}.joblib\") #guardamos con joblib y no con pickle por que estamos usando el ecosiste de scikit learn y en la documentacion es el standard\n",
    "                                               # esta mas optimizado para objetos grandes con arrays numpy y eso lo hace mas eficiente con modelos sklearn\n",
    "registry = {\n",
    "    \"default_model\": \"rf\",\n",
    "    \"available_models\": list(trained_models.keys())\n",
    "}\n",
    "\n",
    "with open(\"models/registry.json\", \"w\") as f:\n",
    "    json.dump(registry, f, indent=2)\n",
    "\n",
    "print(\"Modelos guardados en /models\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OAP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
